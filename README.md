#  News ETL Pipeline

![Python](https://img.shields.io/badge/Python-3.8+-blue) ![SQLite](https://img.shields.io/badge/SQLite-Database-orange) 

Python | SQLite | News API | ETL

---

## âœ¨ Introduction

Welcome to the **News ETL Pipeline Project** ğŸš€

This repository demonstrates how to build a **ETL pipeline** that extracts news articles from a public API, transforms the data, and loads it into a **SQLite database**.

Itâ€™s designed as a showcase of **Data Engineering best practices**: modular Python scripts, clear task separation (Extract â†’ Transform â†’ Load), and an orchestrated workflow.

---

## âš™ï¸ Tech Stack

| Tool/Service        | Role                                              |
| ------------------- | ------------------------------------------------- |
| ğŸ“° News API         | Source of articles published in the last 24 hours |
| ğŸ Python           | Orchestrates ETL tasks                            |
| ğŸ—„ SQLite           | Stores transformed news data                      |
| ğŸ”„ Python Scripts   | Modular Extract, Transform, Load logic            |
| ğŸ“‚ Folder Structure | Organizes code & reusable components              |

---

## ğŸ—‚ Repository Structure

```
dags/
etl/
    extract_news.py        # Extract news articles from the API
    transform_news.py      # Clean & transform the data
    load_news.py           # Load transformed data into SQLite
news_etl_script.py         # Orchestrates all ETL tasks
__pycache__/               # Python cache files
README.md
```

---

## ğŸš€ Pipeline Overview

**Task Flow:**

```
extract_task â†’ transform_task â†’ load_task
```

1ï¸âƒ£ **Extract (`extract_news.py`)**

* Fetches `author`, `content`, `source`, `title`, `publish_date`
* Only articles published in the **last 24 hours**

2ï¸âƒ£ **Transform (`transform_news.py`)**

* Converts text to **lowercase**
* Converts column datatypes (e.g., `publish_date` â†’ datetime)
* Cleans data (removes nulls, trims spaces)

3ï¸âƒ£ **Load (`load_news.py`)**

* Stores the cleaned data into a **SQLite database** (`news.db`)
* Creates table if it doesnâ€™t exist

4ï¸âƒ£ **Orchestration (`news_etl_script.py`)**

* Runs ETL tasks sequentially: **Extract â†’ Transform â†’ Load**

---

## ğŸ“ˆ Key Learnings

* Build ETL pipeline in Python
* Extract data from APIs and handle JSON responses
* Transform and clean data for analytics
* Load and manage data in SQLite
* Orchestrate ETL tasks sequentially

---

## ğŸš§ Future Enhancements

* ğŸ” Add **data quality checks** (missing values, duplicates)
* â˜ Migrate to **BigQuery** for larger datasets
* ğŸ“Š Add **analytics-ready views** or dashboards
